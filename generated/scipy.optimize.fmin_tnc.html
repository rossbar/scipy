<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8">
    
    <title>scipy.optimize.fmin_tnc &mdash; SciPy v1.5.0.dev0+47ffc1e Reference Guide</title>
    
    <link rel="stylesheet" type="text/css" href="../_static/css/spc-bootstrap.css">
    <link rel="stylesheet" type="text/css" href="../_static/css/spc-extend.css">
    <link rel="stylesheet" href="../_static/scipy.css" type="text/css" >
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" >
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1.5.0.dev0+47ffc1e',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  false
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script type="text/javascript" src="../_static/scipy-mathjax/MathJax.js?config=scipy-mathjax"></script>
    <script type="text/javascript" src="../_static/js/copybutton.js"></script>
    <link rel="index" title="Index" href="../genindex.html" >
    <link rel="search" title="Search" href="../search.html" >
    <link rel="top" title="SciPy v1.5.0.dev0+47ffc1e Reference Guide" href="../index.html" >
    <link rel="up" title="Optimization and root finding (scipy.optimize)" href="../optimize.html" >
    <link rel="next" title="scipy.optimize.fmin_cobyla" href="scipy.optimize.fmin_cobyla.html" >
    <link rel="prev" title="scipy.optimize.fmin_l_bfgs_b" href="scipy.optimize.fmin_l_bfgs_b.html" > 
  </head>
  <body>

<div class="container">
  <div class="top-scipy-org-logo-header">
    <a href="../index.html">
      <img style="border: 0;" alt="SciPy" src="../_static/img/scipy_org_logo.png"></a>
    </div>
  </div>
</div>


    <div class="container">
      <div class="main">
        
	<div class="row-fluid">
	  <div class="span12">
	    <div class="spc-navbar">
              
    <ul class="nav nav-pills pull-left">
        <li class="active"><a href="https://scipy.org/">SciPy.org</a></li>
        <li class="active"><a href="https://docs.scipy.org/">Docs</a></li>
	
        <li class="active"><a href="../index.html">SciPy v1.5.0.dev0+47ffc1e Reference Guide</a></li>
	
          <li class="active"><a href="../optimize.html" accesskey="U">Optimization and root finding (<code class="xref py py-mod docutils literal notranslate"><span class="pre">scipy.optimize</span></code>)</a></li> 
    </ul>
              
              
    <ul class="nav nav-pills pull-right">
      <li class="active">
        <a href="../genindex.html" title="General Index"
           accesskey="I">index</a>
      </li>
      <li class="active">
        <a href="../py-modindex.html" title="Python Module Index"
           >modules</a>
      </li>
      <li class="active">
        <a href="scipy.optimize.fmin_cobyla.html" title="scipy.optimize.fmin_cobyla"
           accesskey="N">next</a>
      </li>
      <li class="active">
        <a href="scipy.optimize.fmin_l_bfgs_b.html" title="scipy.optimize.fmin_l_bfgs_b"
           accesskey="P">previous</a>
      </li>
    </ul>
              
	    </div>
	  </div>
	</div>
        

	<div class="row-fluid">
          <div class="span9">
            
        <div class="bodywrapper">
          <div class="body" id="spc-section-body">
            
  <div class="section" id="scipy-optimize-fmin-tnc">
<h1>scipy.optimize.fmin_tnc<a class="headerlink" href="#scipy-optimize-fmin-tnc" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="scipy.optimize.fmin_tnc">
<code class="sig-prename descclassname">scipy.optimize.</code><code class="sig-name descname">fmin_tnc</code><span class="sig-paren">(</span><em class="sig-param">func</em>, <em class="sig-param">x0</em>, <em class="sig-param">fprime=None</em>, <em class="sig-param">args=()</em>, <em class="sig-param">approx_grad=0</em>, <em class="sig-param">bounds=None</em>, <em class="sig-param">epsilon=1e-08</em>, <em class="sig-param">scale=None</em>, <em class="sig-param">offset=None</em>, <em class="sig-param">messages=15</em>, <em class="sig-param">maxCGit=-1</em>, <em class="sig-param">maxfun=None</em>, <em class="sig-param">eta=-1</em>, <em class="sig-param">stepmx=0</em>, <em class="sig-param">accuracy=0</em>, <em class="sig-param">fmin=0</em>, <em class="sig-param">ftol=-1</em>, <em class="sig-param">xtol=-1</em>, <em class="sig-param">pgtol=-1</em>, <em class="sig-param">rescale=-1</em>, <em class="sig-param">disp=None</em>, <em class="sig-param">callback=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scipy/scipy/blob/47ffc1e/scipy/optimize/tnc.py#L86-L277"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#scipy.optimize.fmin_tnc" title="Permalink to this definition">¶</a></dt>
<dd><p>Minimize a function with variables subject to bounds, using
gradient information in a truncated Newton algorithm. This
method wraps a C implementation of the algorithm.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>func</strong><span class="classifier">callable <code class="docutils literal notranslate"><span class="pre">func(x,</span> <span class="pre">*args)</span></code></span></dt><dd><p>Function to minimize.  Must do one of:</p>
<ol class="arabic simple">
<li><p>Return f and g, where f is the value of the function and g its
gradient (a list of floats).</p></li>
<li><p>Return the function value but supply gradient function
separately as <em class="xref py py-obj">fprime</em>.</p></li>
<li><p>Return the function value and set <code class="docutils literal notranslate"><span class="pre">approx_grad=True</span></code>.</p></li>
</ol>
<p>If the function returns None, the minimization
is aborted.</p>
</dd>
<dt><strong>x0</strong><span class="classifier">array_like</span></dt><dd><p>Initial estimate of minimum.</p>
</dd>
<dt><strong>fprime</strong><span class="classifier">callable <code class="docutils literal notranslate"><span class="pre">fprime(x,</span> <span class="pre">*args)</span></code>, optional</span></dt><dd><p>Gradient of <em class="xref py py-obj">func</em>. If None, then either <em class="xref py py-obj">func</em> must return the
function value and the gradient (<code class="docutils literal notranslate"><span class="pre">f,g</span> <span class="pre">=</span> <span class="pre">func(x,</span> <span class="pre">*args)</span></code>)
or <em class="xref py py-obj">approx_grad</em> must be True.</p>
</dd>
<dt><strong>args</strong><span class="classifier">tuple, optional</span></dt><dd><p>Arguments to pass to function.</p>
</dd>
<dt><strong>approx_grad</strong><span class="classifier">bool, optional</span></dt><dd><p>If true, approximate the gradient numerically.</p>
</dd>
<dt><strong>bounds</strong><span class="classifier">list, optional</span></dt><dd><p>(min, max) pairs for each element in x0, defining the
bounds on that parameter. Use None or +/-inf for one of
min or max when there is no bound in that direction.</p>
</dd>
<dt><strong>epsilon</strong><span class="classifier">float, optional</span></dt><dd><p>Used if approx_grad is True. The stepsize in a finite
difference approximation for fprime.</p>
</dd>
<dt><strong>scale</strong><span class="classifier">array_like, optional</span></dt><dd><p>Scaling factors to apply to each variable. If None, the
factors are up-low for interval bounded variables and
1+|x| for the others. Defaults to None.</p>
</dd>
<dt><strong>offset</strong><span class="classifier">array_like, optional</span></dt><dd><p>Value to subtract from each variable. If None, the
offsets are (up+low)/2 for interval bounded variables
and x for the others.</p>
</dd>
<dt><strong>messages</strong><span class="classifier">int, optional</span></dt><dd><p>Bit mask used to select messages display during
minimization values defined in the MSGS dict. Defaults to
MGS_ALL.</p>
</dd>
<dt><strong>disp</strong><span class="classifier">int, optional</span></dt><dd><p>Integer interface to messages. 0 = no message, 5 = all messages</p>
</dd>
<dt><strong>maxCGit</strong><span class="classifier">int, optional</span></dt><dd><p>Maximum number of hessian*vector evaluations per main
iteration. If maxCGit == 0, the direction chosen is
-gradient if maxCGit &lt; 0, maxCGit is set to
max(1,min(50,n/2)). Defaults to -1.</p>
</dd>
<dt><strong>maxfun</strong><span class="classifier">int, optional</span></dt><dd><p>Maximum number of function evaluation. If None, maxfun is
set to max(100, 10*len(x0)). Defaults to None.</p>
</dd>
<dt><strong>eta</strong><span class="classifier">float, optional</span></dt><dd><p>Severity of the line search. If &lt; 0 or &gt; 1, set to 0.25.
Defaults to -1.</p>
</dd>
<dt><strong>stepmx</strong><span class="classifier">float, optional</span></dt><dd><p>Maximum step for the line search. May be increased during
call. If too small, it will be set to 10.0. Defaults to 0.</p>
</dd>
<dt><strong>accuracy</strong><span class="classifier">float, optional</span></dt><dd><p>Relative precision for finite difference calculations. If
&lt;= machine_precision, set to sqrt(machine_precision).
Defaults to 0.</p>
</dd>
<dt><strong>fmin</strong><span class="classifier">float, optional</span></dt><dd><p>Minimum function value estimate. Defaults to 0.</p>
</dd>
<dt><strong>ftol</strong><span class="classifier">float, optional</span></dt><dd><p>Precision goal for the value of f in the stopping criterion.
If ftol &lt; 0.0, ftol is set to 0.0 defaults to -1.</p>
</dd>
<dt><strong>xtol</strong><span class="classifier">float, optional</span></dt><dd><p>Precision goal for the value of x in the stopping
criterion (after applying x scaling factors). If xtol &lt;
0.0, xtol is set to sqrt(machine_precision). Defaults to
-1.</p>
</dd>
<dt><strong>pgtol</strong><span class="classifier">float, optional</span></dt><dd><p>Precision goal for the value of the projected gradient in
the stopping criterion (after applying x scaling factors).
If pgtol &lt; 0.0, pgtol is set to 1e-2 * sqrt(accuracy).
Setting it to 0.0 is not recommended. Defaults to -1.</p>
</dd>
<dt><strong>rescale</strong><span class="classifier">float, optional</span></dt><dd><p>Scaling factor (in log10) used to trigger f value
rescaling. If 0, rescale at each iteration. If a large
value, never rescale. If &lt; 0, rescale is set to 1.3.</p>
</dd>
<dt><strong>callback</strong><span class="classifier">callable, optional</span></dt><dd><p>Called after each iteration, as callback(xk), where xk is the
current parameter vector.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>x</strong><span class="classifier">ndarray</span></dt><dd><p>The solution.</p>
</dd>
<dt><strong>nfeval</strong><span class="classifier">int</span></dt><dd><p>The number of function evaluations.</p>
</dd>
<dt><strong>rc</strong><span class="classifier">int</span></dt><dd><p>Return code, see below</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="scipy.optimize.minimize.html#scipy.optimize.minimize" title="scipy.optimize.minimize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">minimize</span></code></a></dt><dd><p>Interface to minimization algorithms for multivariate functions. See the ‘TNC’ <em class="xref py py-obj">method</em> in particular.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The underlying algorithm is truncated Newton, also called
Newton Conjugate-Gradient. This method differs from
scipy.optimize.fmin_ncg in that</p>
<ol class="arabic simple">
<li><p>it wraps a C implementation of the algorithm</p></li>
<li><p>it allows each variable to be given an upper and lower bound.</p></li>
</ol>
<p>The algorithm incorporates the bound constraints by determining
the descent direction as in an unconstrained truncated Newton,
but never taking a step-size large enough to leave the space
of feasible x’s. The algorithm keeps track of a set of
currently active constraints, and ignores them when computing
the minimum allowable step size. (The x’s associated with the
active constraint are kept fixed.) If the maximum allowable
step size is zero then a new constraint is added. At the end
of each iteration one of the constraints may be deemed no
longer active and removed. A constraint is considered
no longer active is if it is currently active
but the gradient for that variable points inward from the
constraint. The specific constraint removed is the one
associated with the variable of largest index whose
constraint is no longer active.</p>
<p>Return codes are defined as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span> <span class="n">Infeasible</span> <span class="p">(</span><span class="n">lower</span> <span class="n">bound</span> <span class="o">&gt;</span> <span class="n">upper</span> <span class="n">bound</span><span class="p">)</span>
 <span class="mi">0</span> <span class="p">:</span> <span class="n">Local</span> <span class="n">minimum</span> <span class="n">reached</span> <span class="p">(</span><span class="o">|</span><span class="n">pg</span><span class="o">|</span> <span class="o">~=</span> <span class="mi">0</span><span class="p">)</span>
 <span class="mi">1</span> <span class="p">:</span> <span class="n">Converged</span> <span class="p">(</span><span class="o">|</span><span class="n">f_n</span><span class="o">-</span><span class="n">f_</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">|</span> <span class="o">~=</span> <span class="mi">0</span><span class="p">)</span>
 <span class="mi">2</span> <span class="p">:</span> <span class="n">Converged</span> <span class="p">(</span><span class="o">|</span><span class="n">x_n</span><span class="o">-</span><span class="n">x_</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">|</span> <span class="o">~=</span> <span class="mi">0</span><span class="p">)</span>
 <span class="mi">3</span> <span class="p">:</span> <span class="n">Max</span><span class="o">.</span> <span class="n">number</span> <span class="n">of</span> <span class="n">function</span> <span class="n">evaluations</span> <span class="n">reached</span>
 <span class="mi">4</span> <span class="p">:</span> <span class="n">Linear</span> <span class="n">search</span> <span class="n">failed</span>
 <span class="mi">5</span> <span class="p">:</span> <span class="n">All</span> <span class="n">lower</span> <span class="n">bounds</span> <span class="n">are</span> <span class="n">equal</span> <span class="n">to</span> <span class="n">the</span> <span class="n">upper</span> <span class="n">bounds</span>
 <span class="mi">6</span> <span class="p">:</span> <span class="n">Unable</span> <span class="n">to</span> <span class="n">progress</span>
 <span class="mi">7</span> <span class="p">:</span> <span class="n">User</span> <span class="n">requested</span> <span class="n">end</span> <span class="n">of</span> <span class="n">minimization</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Wright S., Nocedal J. (2006), ‘Numerical Optimization’</p>
<p>Nash S.G. (1984), “Newton-Type Minimization Via the Lanczos Method”,
SIAM Journal of Numerical Analysis 21, pp. 770-778</p>
</dd></dl>

</div>


          </div>
        </div>
          </div>
      <div class="spc-rightsidebar span3">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="scipy.optimize.fmin_l_bfgs_b.html"
                        title="previous chapter">scipy.optimize.fmin_l_bfgs_b</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="scipy.optimize.fmin_cobyla.html"
                        title="next chapter">scipy.optimize.fmin_cobyla</a></p>
<div id="searchbox" style="display: none" role="search">
  <h4>Quick search</h4>
    <div>
    <form class="search" action="../search.html" method="get">
      <input type="text" style="width: inherit;" name="q" />
      <input type="submit" value="search" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
        </div>
      </div>
    </div>

    <div class="container container-navbar-bottom">
      <div class="spc-navbar">
        
      </div>
    </div>
    <div class="container">
    <div class="footer">
    <div class="row-fluid">
    <ul class="inline pull-left">
      <li>
        &copy; Copyright 2008-2019, The SciPy community.
      </li>
      <li>
      Last updated on Dec 16, 2019.
      </li>
      <li>
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 2.3.0.
      </li>
    </ul>
    </div>
    </div>
    </div>
  </body>
</html>